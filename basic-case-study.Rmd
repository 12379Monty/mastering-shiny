# Case study: CRAN download logs {#basic-case-study}

```{r include=FALSE}
source("common.R")
```

## Introduction

Now let's walk through an example of an ordinary R script for downloading, aggregating, and visualizing some data.

This script downloads and parses the download logs for a specific date. The logs are in compressed CSV format and contain one row per download; on 2019-02-20, the number of rows was 3,437,899.

The columns are:

* `date`
* `time`
* `size` (in bytes)
* `r_version`, the version of R, binary packages only
* `r_arch`, the machine architecture (e.g. `"x86_64"` or `"i386"`), binary packages only
* `r_os`, the operating system, binary packages only
* `package`, the package being requested
* `version`, the exact version of the package being requested
* `country`
* `ip_id`, an anonymized identifier for the IP address of the requestor

After downloading the data, the script will tally the number of rows (downloads) with each value in a specified column. For example, if we specify the `package` column, then we get the number of times each package was downloaded; if we specify the `r_os` column, we get the number of downloads from each operating system.

Once the tallying is done, we'll plot this data in a couple of ways. We'll zoom in on the top few most popular values (e.g. the most popular packages), and we'll also visualize all the values to get a sense of the "long tail", to show how quickly the downloads decrease as we move down the list of packages.

Now, on to the code. First, we'll load the libraries we need.

```{r, message = FALSE}
library(lubridate)
library(readr)
library(dplyr)
library(ggplot2)
library(gt)
```

Next, we'll introduce **configuration variables** that can be modified to look at different dates or tally by different dimensions, or to change the number of top values to focus on. (Not to look too far ahead, but these are values we might eventually want to turn into interactive inputs.)

```{r cache=TRUE}
# A. Configuration variables
date <- "2019-02-20"
dimension <- "package"  # r_version, r_arch, r_os, package, country, ip_id
top_count <- 20L
```

Now we begin the real work of the script. **Downloading and parsing the data** will be by far the most time-consuming portions, and we'll use `readr::read_csv` to accomplish both in one step.

```{r cache=TRUE,message=FALSE}
## Downloading and parsing =========

# B. Form URL for downloading
url <- sprintf("http://cran-logs.rstudio.com/%s/%s.csv.gz", year(date), date)

# C. Download/parse data
download_data <- read_csv(url)
```

```{r echo=FALSE}
attr(download_data, "spec") <- NULL
str(download_data, 5)
```

Now that the data is in memory, we will perform the **data manipulation**. The implementation details here are not that important; just understand that we're taking the `download_data` data frame from above, with its 3.4 million rows, and turning it into counts of rows grouped by the dimension in question (`package`).

```{r data_manip,cache=TRUE}
## Data manipulation =========

# D. Count observations, grouping by the desired dimension
by_frequency <- download_data %>%
  pull(dimension) %>%
  table() %>%
  sort(decreasing = TRUE) %>%
  as_tibble() %>%
  setNames(c(dimension, "downloads"))

# E. Limit to the top `top_count`
most_frequent <- by_frequency %>%
  head(top_count)
```

Here's the resulting `by_frequency` data frame. `most_frequent` is identical, but limited to the top `r top_count` rows.

```{r echo=FALSE}
str(most_frequent)
```

Now we're ready to **plot our data**; one bar plot using `most_frequent`, and one line plot using the full `by_frequency`.

```{r ggplots,cache=TRUE,results="hold"}
## Various outputs =========

# F. Plot the top values
ggplot(most_frequent, aes_string(x = dimension)) +
  geom_bar(aes(y = downloads / 1000), stat = "identity") +
  ylab("Downloads (thousands)") +
  coord_flip() +
  scale_x_discrete(limits = rev(most_frequent[[dimension]])) +
  ggtitle(paste0("CRAN download counts by ", dimension))

# G. Plot all of the counts, by rank ("long tail")
ggplot(by_frequency, aes(x = seq_along(downloads), y = downloads)) +
  geom_line() +
  xlab("Rank") +
  scale_y_log10() +
  ggtitle(paste0("CRAN download counts by ", dimension, " rank"))
```

You can see the entire script at [TODO: LINK].

## Making an app

To transform this code into a Shiny app, we need to answer a few questions:

### 1. What are the inputs for the user to provide?

Fortunately, our script gathered all the configurable variables at the top: `date`, `dimension`, `top_count`. The only work for us to do here is to use `dateInput`, `selectInput`, and `numericInput`, respectively, in the UI section of our app, and then change references to these variables in the server function to `input$date`, `input$dimension`, and `input$top_count`.

### 2. What are the conceptual "steps" performed in the script?

You can already tell by the code comments above that I've divided the work into discrete steps. Incidentally, this is good practice anyway, as is breaking larger scripts into smaller functions (which I did not do in this case). Whatever form of subdivision you use, breaking down the problem into smaller subproblems makes our code easier to write, read, and debug.

I've summarized these steps in the table below.

|Step|Variable       |Description|
|----|---------------|-----------|
|A   |`date`, `dimension`, `top_count`|Configuration variables|
|B   |`url`          |Form URL for downloading|
|C   |`download_df`  |Download/parse data|
|D   |`by_frequency` |Count observations, grouping by the desired dimension|
|E   |`most_frequent`|Limit to the top `top_count`|
|F   |               |Plot the top values|
|G   |               |Plot all of the counts|

This is the breakdown I'm using, but there isn't one single correct arrangement of steps; you may consider steps B and C to really be a single step, or for step D to be composed of multiple steps (e.g. for summarizing, sorting, and converting to a tibble to all be individual steps). These changes wouldn't cause any noticeable change in the readability of our code or the performance of our app.

But just because there isn't a single right answer, does _not_ mean there are no wrong answers! We'll discuss some of the factors we want to consider in a section below. [TODO: xref]

### 3. For each of the steps performed: is it a _calculation_, an _output_, or a _task_?

To answer this question, ask yourself two questions: Does this step return a value? And if so, is the return value the _only_ reason this task would ever be useful? If the answer to both of these questions is "yes", then you have a calculation.

For example, in step C, we download and parse the data in one step. Yes, there is a return value--it's the data frame. And yes, the only reason you would call `read_csv(url)` is because you want the data frame.

Note that it might be a different story if we performed the download in a separate `download.file(url, destfile)` step; in that case, downloading the data to a known location might be a useful end, in and of itself. In that case, the downloading could be considered a separate task.

On the other side, step F--plotting the top values--is an output.

Once we've categorized each step, we go through the fairly mechanical process of turning each calculation into a reactive expression, and each task into an observer or output. For example, steps B and C are changed from this:

```{r eval=FALSE}
# B. Form URL for downloading
url <- sprintf("http://cran-logs.rstudio.com/%s/%s.csv.gz",
    year(input$date), input$date)

# C. Download/parse data
download_data <- read_csv(url)
```

To this:

```{r eval=FALSE}
# B. Form URL for downloading
url <- reactive({
  sprintf("http://cran-logs.rstudio.com/%s/%s.csv.gz",
    year(input$date), input$date)
})

# C. Download/parse data
download_data <- reactive({
  read_csv(url())
})
```

Rather than assigning the value of `sprintf(...)` to `url`, we create a reactive expression using `reactive()`. And when the `download_data` reactive expression wants to access the URL, it uses `url()` instead of `url`.

For each output, you need to take the additional step of deciding the type of the output (e.g. plot, table, or text) and choosing the output/render function pair that corresponds to that type (`plotOutput`/`renderPlot`, `tableOutput`/`renderTable`, `verbatimTextOutput`/`renderPrint`). Our step F goes from this:

```{r eval=FALSE}
# F. Plot the top values
ggplot(most_frequent, aes_string(x = dimension)) +
  geom_bar(aes(y = downloads / 1000), stat = "identity") +
  ylab("Downloads (thousands)") +
  coord_flip() +
  scale_x_discrete(limits = rev(most_frequent[[dimension]])) +
  ggtitle(paste0("CRAN download counts by ", dimension))
```

To this:

```{r eval=FALSE}
# F. Plot the top values
output$plot_top_values <- renderPlot({
  ggplot(most_frequent(), aes_string(x = dimension)) +
    geom_bar(aes(y = downloads / 1000), stat = "identity") +
    ylab("Downloads (thousands)") +
    coord_flip() +
    scale_x_discrete(limits = rev(most_frequent()[[dimension]])) +
    ggtitle(paste0("CRAN download counts by ", dimension))
})
```
